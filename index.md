## My Portfolio

---

### NLP 
[Overview of NLP by Farishah](https://farishah.github.io/CS6301-NLP/Overview%20of%20NLP.pdf)
<br><br>
Natural Language Processing interests me because there are many research and career opportunities in the field of Software Engineering, dealing with AI, Machine Learning, and NLP. At my current job, NLP is used in the website search engine and Customer Service chatbot, so I found it extremely helpful to understand the intricacies of NLP to make the internal system more intuitive and intelligent for customers.

NLP is an exciting and growing field that could help solve real-world problems, especially in the finance and customer-service industry, where I specialize. To keep up with this field, this course has inspired me to subscribe to podcasts and newsletters, to help me keep up with all the new versions of technologies and frameworks that are emerging.

Learning about NLP inspires me to venture out and create more NLP-driven personal projects that could potentially help solve real-world problems outside of the professional and corporate bubble. I had experiences in machine learning and big data from the courses I took in my Master's program, thus adding NLP to my belt of knowledge helps me to help others in this rapidly growing field. It was exciting to use NLTK, Scrapy, Python Requests Library, Python sqlite3, SKLearn, Pandas, Numpy, Keras, Tensorflow in almost all of the projects this semester.


Overall, I have grown great enthusiasm for NLP and plan to keep up with this rapidly changing field by staying updated on the latest research and technologies.

---

### Word Guessing Game
Used Python and NLTK features to explore a text file (one chapter of an anatomy textbook) to create a word guessing game.
<br><br>
![](https://user-images.githubusercontent.com/42190218/233822247-f84de84a-9ae7-42d9-9c96-6036a804f48b.gif)
<br><br>
<a href="https://github.com/farishah/CS6301-NLP/tree/main/FarishahNahrin_Chapter5">View Code on GitHub</a>
<br><br>
<img src="https://img.shields.io/badge/Python-white?logo=Python">

---

### Web Crawler

Built a web crawler function that scrapes contents from virtualbangladesh.com, determined the top terms using NLP techniques, and saved contents to a knowledge base. 
<br><br>
![](https://user-images.githubusercontent.com/42190218/233821950-89659365-078d-486c-8f1a-a27a5377efd1.gif)
<br><br>
[My Web Crawler Report](https://farishah.github.io/CS6301-NLP/FarishahNahrin_WebCrawler/Report_FarishahNahrin.pdf)
<br><br>
<a href="https://github.com/farishah/CS6301-NLP/tree/main/FarishahNahrin_WebCrawler">View Code on GitHub</a>
<br><br>
<img src="https://img.shields.io/badge/Python-white?logo=Python">

---

### WordNet

WordNet is a "lexical database of nouns, verbs, adjectives and adverbs that provides short definitions called glosses, and use examples." Identified sysnets, hypernyms, hyponyms, etc., from nouns using WordNet and SentiWordNet.
<br><br>
<a href="https://github.com/farishah/CS6301-NLP/blob/main/Farishah_Wordnet.ipynb">View Code on GitHub</a>
<br><br>
<img src="https://img.shields.io/badge/Python-white?logo=Python">

---

### N-Grams

Created bigram and unigram dictionaries for English, French, and Italian, using the provided training data, where the key is the unigram or bigram text and the value is the count of that unigram or bigram in the data. Then, calculated probabilities for each language and compare against the true labels. 
<br><br>
[N-Grams Narrative](https://farishah.github.io/CS6301-NLP/Farishah_Ngrams/Farishah_Narrative_Ngrams.pdf)
<br><br>
<a href="https://github.com/farishah/CS6301-NLP/tree/main/Farishah_Ngrams">View Code on GitHub</a>
<br><br>
<img src="https://img.shields.io/badge/Python-white?logo=Python">

---

### Sentence Parsing

Crafted a sentence and identified the PSG (Parse Structure Grammar) tree, parts-of-speech, depedency parse, depedency relations, SRL (Semantic Role Labeling) parse using CoreNLP and AllenNLP.  
<br>
[Sentence Parsing Report](https://farishah.github.io/CS6301-NLP/Farishah_Nahrin_Sentence_Parsing.pdf)

---

### Chatbot Project

Created a chatbot from scratch with NLP techniques, using the web scraped virtualbangladesh.com data. Maintained a user model within chatbot system. 
<br><br>
![](https://user-images.githubusercontent.com/42190218/233819348-b88a6870-9fdf-48e7-8c4e-20f7c39bea41.gif)
<br><br>
[Chatbot Report](https://farishah.github.io/CS6301-NLP/ChatbotReport_FarishahNahrin.pdf)
<br><br>
<a href="https://github.com/farishah/CS6301-NLP/tree/main/FarishahNahrin_ChatBot">View Code on GitHub</a>
<br><br>
<img src="https://img.shields.io/badge/Python-white?logo=Python">

---

### ACL Paper Summary

Reflected on the 'Clickbait Spoiling via Question Answering and Passage Retrieval
Matthias Hagen, Maik Fr√∂be, Artur Jurk, Martin Potthast' Conference paper and analyzed the research presented in the paper.
<br><br>
[ACL Paper Summary](https://farishah.github.io/CS6301-NLP/Farishah_Nahrin_ACL_Summary.pdf)

---

### Text Classification Part 1 

Used the [Email Spam Classification dataset](https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv) to perform Naive Bayes, Logistic Regression, and Neural Networks in order to determine how accurate each Machine Learning algorithm is, in determining whether the email is spam or not spam. 
<br><br>
[View Code on Github](https://github.com/farishah/CS6301-NLP/tree/main/Farishah_Text_Classification_1)
<br><br>
<img src="https://img.shields.io/badge/Python-white?logo=Python">

---

### Text Classification Part 2

Used the [Women's E-Commerce Clothing Reviews dataset](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews) to perform LTSM, CNN, and different Embedding approaches to determine which model can predict whether a customer would recommend a product based on the customer's review text.
<br><br>
[View Code on Github](https://github.com/farishah/CS6301-NLP/tree/main/Farishah_Text_Classification_2)
<br><br>
<img src="https://img.shields.io/badge/Python-white?logo=Python">

---
<p style="font-size:11px">Page template forked from <a href="https://github.com/evanca/quick-portfolio">evanca</a></p>
<!-- Remove above link if you don't want to attibute -->
